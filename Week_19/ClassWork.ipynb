{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import Isomap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take one of the supervised learning models you have built recently and apply at least\n",
    "three dimensionality reduction techniques to it (separately). Be sure to create a short\n",
    "summary of each technique you use. Indicate how each changed the model\n",
    "performance. Reference:\n",
    "https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"../week_13/diabetes.csv\")\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Define a Standard Scaler to normalize inputs\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a statistical process that turns a series of observations of possibly correlated variables into a set of principle component values, which are linearly uncorrelated variables. PCA is frequently used to simplify data, decrease noise, and identify unmeasured \"latent variables,\" to put it another way. This implies PCA will assist us in identifying a smaller number of features that will compress our original dataset, capturing up to a percentage of its variation depending on the number of new features we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation and classifier regularization.\n",
    "pca = PCA(n_components=8,random_state=42)\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "pca_model = Pipeline(steps=[(\"pca\", pca), (\"logistic\", logistic)])\n",
    "\n",
    "# evaluate model\n",
    "pca_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "pca_scores = cross_val_score(pca_model, X, y, scoring='accuracy', cv=pca_cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (np.mean(pca_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA chooses new axes for dimensions such that variance (and hence the â€˜shapeâ€™) of the data is preserved, LDA chooses new axes such that the separability between two classes is optimized.\n",
    "\n",
    "The likelihood that a new set of inputs belongs to each class is estimated using linear discriminant analysis. The output class with the highest probability is chosen. The LDA makes its prediction in this manner. To estimate probabilities, LDA employs Bayes' Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "lda=LinearDiscriminantAnalysis(n_components=1)\n",
    "lda_model = Pipeline(steps=[(\"lda\", lda), (\"logistic\", logistic)])\n",
    "\n",
    "# evaluate model\n",
    "lda_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "lda_scores = cross_val_score(lda_model, X, y, scoring='accuracy', cv=lda_cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (np.mean(lda_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Principle Component Analysis, Isomap (Isometric Feature Mapping) is a non-linear feature reduction approach.\n",
    "It employs a KNN technique to locate each data point's k closest neighbors. Once the neighbors have been identified, the neighborhood graph is created, with dots connecting to each other if they are neighbors. The shortest path between each pair of data points is then computed (nodes). Finally, it computes lower-dimensional embeddings via multidimensional scaling (MDS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723\n"
     ]
    }
   ],
   "source": [
    "iso = Isomap(n_components=10)\n",
    "iso_model = Pipeline(steps=[(\"iso\", iso), (\"logistic\", logistic)])\n",
    "\n",
    "iso_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "iso_scores = cross_val_score(iso_model, X, y, scoring='accuracy', cv=iso_cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (np.mean(iso_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that will indicate if an inputted IPv4 address is accurate or not.\n",
    "IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated\n",
    "by periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IP_addr(IP_address ):\n",
    "    values = IP_address.split('.')\n",
    "    if len(values) != 4:\n",
    "        return False\n",
    "    for num in values:\n",
    "        if int(num)> 255 or int(num)<0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IP_addr('2.33.245.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IP_addr('12.345.67.89')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
