{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "# #Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9314,  2.0179,  0.7807,  ...,  0.4315, -0.3748,  0.6321],\n",
      "        [ 0.6326, -1.1486,  0.4654,  ..., -0.1198, -0.2942,  0.7170],\n",
      "        [-0.5625, -0.4769, -0.2703,  ..., -0.2096,  2.7452,  0.0381],\n",
      "        ...,\n",
      "        [-0.8613, -0.7648,  0.0450,  ...,  0.7648, -0.7838, -0.3014],\n",
      "        [ 0.6326,  2.2099,  1.2010,  ...,  0.4315, -0.6047,  2.7537],\n",
      "        [ 0.0351,  0.7385, -0.5856,  ..., -0.3378, -0.5778,  0.2927]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #where the activation functions are\n",
    "\n",
    "#create tensors = matrices \n",
    "X_train = torch.FloatTensor(X_train) \n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artificial neural network\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=8,hidden1=20,hidden2=20,out_features=2):\n",
    "        super().__init__() #super is a computed indirect reference. So, it isolates changes\n",
    "        # and makes sure that children in the layers of multiple inheritence are calling\n",
    "        #the right parents\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create instance of model\n",
    "ann = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.AdamX(ann.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 0.009586000815033913\n",
      "Epoch number: 11 with loss: 0.009570097550749779\n",
      "Epoch number: 21 with loss: 0.009559844620525837\n",
      "Epoch number: 31 with loss: 0.009551357477903366\n",
      "Epoch number: 41 with loss: 0.009544191882014275\n",
      "Epoch number: 51 with loss: 0.009537060745060444\n",
      "Epoch number: 61 with loss: 0.009530364535748959\n",
      "Epoch number: 71 with loss: 0.009523759596049786\n",
      "Epoch number: 81 with loss: 0.009517444297671318\n",
      "Epoch number: 91 with loss: 0.009511386044323444\n",
      "Epoch number: 101 with loss: 0.009505296126008034\n",
      "Epoch number: 111 with loss: 0.009499643929302692\n",
      "Epoch number: 121 with loss: 0.009493684396147728\n",
      "Epoch number: 131 with loss: 0.009488378651440144\n",
      "Epoch number: 141 with loss: 0.009483672678470612\n",
      "Epoch number: 151 with loss: 0.009477845393121243\n",
      "Epoch number: 161 with loss: 0.009472950361669064\n",
      "Epoch number: 171 with loss: 0.009467746131122112\n",
      "Epoch number: 181 with loss: 0.009463030844926834\n",
      "Epoch number: 191 with loss: 0.009458061307668686\n",
      "Epoch number: 201 with loss: 0.009453236125409603\n",
      "Epoch number: 211 with loss: 0.009448517113924026\n",
      "Epoch number: 221 with loss: 0.009443623945116997\n",
      "Epoch number: 231 with loss: 0.009438922628760338\n",
      "Epoch number: 241 with loss: 0.009434334933757782\n",
      "Epoch number: 251 with loss: 0.009429632686078548\n",
      "Epoch number: 261 with loss: 0.009424994699656963\n",
      "Epoch number: 271 with loss: 0.009420664981007576\n",
      "Epoch number: 281 with loss: 0.009415818378329277\n",
      "Epoch number: 291 with loss: 0.009411614388227463\n",
      "Epoch number: 301 with loss: 0.00940726324915886\n",
      "Epoch number: 311 with loss: 0.009402836672961712\n",
      "Epoch number: 321 with loss: 0.009398195892572403\n",
      "Epoch number: 331 with loss: 0.009393852204084396\n",
      "Epoch number: 341 with loss: 0.009389808401465416\n",
      "Epoch number: 351 with loss: 0.009385461919009686\n",
      "Epoch number: 361 with loss: 0.009380845353007317\n",
      "Epoch number: 371 with loss: 0.0093767074868083\n",
      "Epoch number: 381 with loss: 0.009372575208544731\n",
      "Epoch number: 391 with loss: 0.009368288330733776\n",
      "Epoch number: 401 with loss: 0.009363851509988308\n",
      "Epoch number: 411 with loss: 0.009359882213175297\n",
      "Epoch number: 421 with loss: 0.009355449117720127\n",
      "Epoch number: 431 with loss: 0.00935114175081253\n",
      "Epoch number: 441 with loss: 0.009347204118967056\n",
      "Epoch number: 451 with loss: 0.009342790581285954\n",
      "Epoch number: 461 with loss: 0.009338592179119587\n",
      "Epoch number: 471 with loss: 0.009334532544016838\n",
      "Epoch number: 481 with loss: 0.00933033972978592\n",
      "Epoch number: 491 with loss: 0.009326129220426083\n"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss}')\n",
    "        \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       150\n",
      "           1       0.56      0.51      0.53        81\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.65      0.65      0.65       231\n",
      "weighted avg       0.68      0.69      0.68       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdamX performs the similary like Adam since  Adamax algorithmis a variant of Adam based on infinity norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-f70a38606484>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-f70a38606484>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    return \"there\" + \" are \" + str(len(dv)) + \": \" + \" \".join(str(dv[i]) for i in range(len(dv)) if i != len(dv)- 1 else str(\" and\" + str(dv[i]))\u001b[0m\n\u001b[0m                                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def dv_count(num):\n",
    "    dv = []\n",
    "    \n",
    "    for i in range(1,num+1):\n",
    "        if num%i==0:\n",
    "            dv.append(i)\n",
    "            \n",
    "    if len(dv)==1:\n",
    "        return \"there\" + \" is \" + str(len(dv)) + \": \" +\" \".join(str(e) for e in dv)\n",
    "    else:\n",
    "        return \"there\" + \" are \" + str(len(dv)) + \": \" + \" \".join(str(dv[i]) for i in range(len(dv)) if i != len(dv)- 1 else str(\"and\" + str(dv[i]))\n",
    "    \n",
    "dv_count(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
